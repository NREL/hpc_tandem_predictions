{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3680aaba-6702-4854-aee9-66468e2f6027",
   "metadata": {},
   "source": [
    "## This notebook is used to run hyperparameter optimization studies with Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0499ad0c-35cd-4b56-a55f-4c398bc2ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbatch_pred.runtime_prediction.operation_support import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17f10e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import joblib\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from eagle_jobs.operation_support import train_test_split\n",
    "from eagle_jobs.data_preprocessing import label_encode_columns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbcb79a4-f0e1-4593-ad00-c3d31c8c93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfs():\n",
    "    # Import pkl file\n",
    "    filepath = os.path.join('../data/', 'eagle_data.parquet')\n",
    "    eagle_df = pd.read_parquet(filepath)\n",
    "    eagle_df = eagle_df[eagle_df.state.isin(['COMPLETED','TIMEOUT'])]\n",
    "    \n",
    "    categorical_features = ['user','partition']\n",
    "    label_encode_columns(eagle_df, categorical_features)\n",
    "    \n",
    "    start_time = eagle_df.submit_time.min()\n",
    "    end_time = eagle_df.submit_time.max()\n",
    "    split_times = pd.date_range(start_time, end_time, periods=22)[1:21]\n",
    "    \n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    for split_time in split_times:\n",
    "        train_df, test_df = train_test_split(eagle_df, split_time, training_window=100, testing_window=1)\n",
    "        train_dfs.append(train_df)\n",
    "        test_dfs.append(test_df)\n",
    "    \n",
    "    return train_dfs, test_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2dcb1c7-f2c6-4b56-97ad-d27dc4aaee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs, test_dfs = get_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc69ea0-f774-4adf-b5af-d31c8aa11733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(i, train_dfs, test_dfs):\n",
    "    features = ['wallclock_req','processors_req','mem_req','user','partition']\n",
    "    target = 'run_time'\n",
    "    X_train = train_dfs[i][features]\n",
    "    y_train = train_dfs[i][target]\n",
    "    X_test = test_dfs[i][features]\n",
    "    y_test = test_dfs[i][target]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4974459-d3d2-48e2-8a29-cb2a0c2f30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to fit and evaluate a model with given hyperparameters on a single dataset \n",
    "def fit_model(params):\n",
    "    params['eval_metric'] = 'rmse'\n",
    "    rmse_list = list()\n",
    "    eval_name = 'val'\n",
    "    for i in range(len(train_dfs)):\n",
    "        X_train, y_train, X_test, y_test = load_data(i, train_dfs, test_dfs)\n",
    "        model = XGBRegressor(**params) \n",
    "        model.fit(X_train, y_train) \n",
    "        y_pred = model.predict(X_test) \n",
    "        y_pred = model.predict(X_test) \n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False) \n",
    "        rmse_list.append(rmse)\n",
    "    rmse_avg = sum(rmse_list)/len(rmse_list) / 3600\n",
    "    return sum(rmse_list)/len(rmse_list) / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb47e5-ca40-431b-bd96-2642516a7de7",
   "metadata": {},
   "source": [
    "### Define the objective function.\n",
    "See https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/001_first.html#sphx-glr-tutorial-10-key-features-001-first-py for an introduction to using Optuna for hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "812da308-69c3-4ea3-be83-969443cf65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Save the study before running the next trial\n",
    "    joblib.dump(study, \"../results/optuna_studies/study_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H\") + \".pkl\")\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 200)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 7)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.1, 0.5)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0, 1)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1)\n",
    "    random_state = 42\n",
    "    \n",
    "    params = {'learning_rate': learning_rate, 'subsample': subsample, 'colsample_bytree': colsample_bytree, \\\n",
    "                  'gamma': gamma, 'max_depth': max_depth, 'n_estimators': n_estimators, 'random_state': random_state}\n",
    "    result = fit_model(params)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce73b8c2-feb7-4d08-8b5c-3df9b75cdb48",
   "metadata": {},
   "source": [
    "### If continuing a previous study, set `load_study` to `True` and provide the study name.\n",
    "*Note:* Studies are saved in the `studies` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8003a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_study = True\n",
    "study_name = \"study.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21568a5e-8f94-4035-94c3-77098e4e67a7",
   "metadata": {},
   "source": [
    "### Either load the previous study or create a new study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34ff5265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial until now:\n",
      " Value:  9.270566975521128\n",
      " Params: \n",
      "    n_estimators: 50\n",
      "    max_depth: 6\n",
      "    learning_rate: 0.386232604942757\n",
      "    gamma: 0.9000526173345429\n",
      "    subsample: 0.5724346830456464\n",
      "    colsample_bytree: 0.6279917874378335\n"
     ]
    }
   ],
   "source": [
    "if load_study:\n",
    "    study = joblib.load(\"../results/optuna_studies/\" + study_name)\n",
    "    print(\"Best trial until now:\")\n",
    "    print(\" Value: \", study.best_trial.value)\n",
    "    print(\" Params: \")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "else:\n",
    "    study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f6ac9-735c-49ad-abd7-444cab0829e6",
   "metadata": {},
   "source": [
    "### Run the study.\n",
    "(Increase `n_trials` for better results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daa16b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-10 13:55:56,103]\u001b[0m Trial 10 finished with value: 10.156270852704752 and parameters: {'n_estimators': 143, 'max_depth': 4, 'learning_rate': 0.20555038779640641, 'gamma': 0.718721418030296, 'subsample': 0.822486113548387, 'colsample_bytree': 0.8204176872498461}. Best is trial 0 with value: 9.270566975521128.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 13:57:04,409]\u001b[0m Trial 11 finished with value: 9.935124534726027 and parameters: {'n_estimators': 54, 'max_depth': 6, 'learning_rate': 0.3403906566172594, 'gamma': 0.6741634281618086, 'subsample': 0.5105333649160274, 'colsample_bytree': 0.5137889549351082}. Best is trial 0 with value: 9.270566975521128.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 13:58:20,131]\u001b[0m Trial 12 finished with value: 9.178962558649168 and parameters: {'n_estimators': 51, 'max_depth': 7, 'learning_rate': 0.3740972645086412, 'gamma': 0.978533535354144, 'subsample': 0.845190065929861, 'colsample_bytree': 0.6009457519119111}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 13:59:29,601]\u001b[0m Trial 13 finished with value: 9.52008444423018 and parameters: {'n_estimators': 52, 'max_depth': 6, 'learning_rate': 0.41691312180399337, 'gamma': 0.9829817973111179, 'subsample': 0.6505293949803315, 'colsample_bytree': 0.587750653583109}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:01:28,036]\u001b[0m Trial 14 finished with value: 9.268982696878007 and parameters: {'n_estimators': 82, 'max_depth': 7, 'learning_rate': 0.33097910480444587, 'gamma': 0.7953213500745551, 'subsample': 0.8659867718837675, 'colsample_bytree': 0.6154818921431522}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:03:55,871]\u001b[0m Trial 15 finished with value: 9.570918931805759 and parameters: {'n_estimators': 111, 'max_depth': 7, 'learning_rate': 0.32005512801190583, 'gamma': 0.7998259684419127, 'subsample': 0.9097230673788378, 'colsample_bytree': 0.502242254235124}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:05:49,659]\u001b[0m Trial 16 finished with value: 9.399012560456194 and parameters: {'n_estimators': 85, 'max_depth': 7, 'learning_rate': 0.31556969056565737, 'gamma': 0.8108461706161656, 'subsample': 0.8624509764205864, 'colsample_bytree': 0.5718638361652086}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:07:09,315]\u001b[0m Trial 17 finished with value: 9.530021971047997 and parameters: {'n_estimators': 74, 'max_depth': 5, 'learning_rate': 0.35700695299273005, 'gamma': 0.9992526560587948, 'subsample': 0.92981725556352, 'colsample_bytree': 0.6711652582453528}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:10:05,344]\u001b[0m Trial 18 finished with value: 9.667467318016087 and parameters: {'n_estimators': 128, 'max_depth': 7, 'learning_rate': 0.28950797741953377, 'gamma': 0.6634615023902759, 'subsample': 0.7960683273576077, 'colsample_bytree': 0.5650304758678381}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:11:21,134]\u001b[0m Trial 19 finished with value: 9.39932299276192 and parameters: {'n_estimators': 67, 'max_depth': 5, 'learning_rate': 0.44459131761933207, 'gamma': 0.8145035491738482, 'subsample': 0.8794412691608935, 'colsample_bytree': 0.6486680978470065}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:13:44,121]\u001b[0m Trial 20 finished with value: 9.458140038094957 and parameters: {'n_estimators': 118, 'max_depth': 6, 'learning_rate': 0.4956052333481261, 'gamma': 0.5513035953152173, 'subsample': 0.9987686986889543, 'colsample_bytree': 0.7619715217402583}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:18:27,858]\u001b[0m Trial 21 finished with value: 9.467792386958013 and parameters: {'n_estimators': 197, 'max_depth': 7, 'learning_rate': 0.3653336442190118, 'gamma': 0.8657427258245785, 'subsample': 0.7793397793397943, 'colsample_bytree': 0.6018180738792898}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:19:38,611]\u001b[0m Trial 22 finished with value: 9.566464809466327 and parameters: {'n_estimators': 51, 'max_depth': 6, 'learning_rate': 0.39490847089489733, 'gamma': 0.9188505094044375, 'subsample': 0.7083127597004832, 'colsample_bytree': 0.641326257409523}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:20:58,067]\u001b[0m Trial 23 finished with value: 9.63822499908021 and parameters: {'n_estimators': 64, 'max_depth': 6, 'learning_rate': 0.34270648682137067, 'gamma': 0.8652960056779311, 'subsample': 0.7861756686673811, 'colsample_bytree': 0.5639820256691863}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:23:03,110]\u001b[0m Trial 24 finished with value: 9.296573728351019 and parameters: {'n_estimators': 85, 'max_depth': 7, 'learning_rate': 0.40466941572444304, 'gamma': 0.7478466306040378, 'subsample': 0.8548280515634727, 'colsample_bytree': 0.6130531367090978}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:24:38,499]\u001b[0m Trial 25 finished with value: 9.226036240483106 and parameters: {'n_estimators': 73, 'max_depth': 6, 'learning_rate': 0.43351988382640777, 'gamma': 0.8937918108252954, 'subsample': 0.7028893876787088, 'colsample_bytree': 0.6866479503346161}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:27:08,923]\u001b[0m Trial 26 finished with value: 9.66437995773556 and parameters: {'n_estimators': 94, 'max_depth': 7, 'learning_rate': 0.44028080308244516, 'gamma': 0.9856734807904681, 'subsample': 0.7030316513281699, 'colsample_bytree': 0.698747553505793}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:28:39,680]\u001b[0m Trial 27 finished with value: 9.188689130431184 and parameters: {'n_estimators': 69, 'max_depth': 6, 'learning_rate': 0.4416144277136185, 'gamma': 0.7451365711471944, 'subsample': 0.8245637448478679, 'colsample_bytree': 0.6920249826970648}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:29:56,006]\u001b[0m Trial 28 finished with value: 9.659462890662354 and parameters: {'n_estimators': 64, 'max_depth': 5, 'learning_rate': 0.4590711165829119, 'gamma': 0.6329388021511874, 'subsample': 0.7703754537442443, 'colsample_bytree': 0.6792204257491103}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n",
      "\u001b[32m[I 2023-05-10 14:31:26,056]\u001b[0m Trial 29 finished with value: 9.288564729704747 and parameters: {'n_estimators': 73, 'max_depth': 6, 'learning_rate': 0.43829141552703876, 'gamma': 0.7382407166943794, 'subsample': 0.8194357843887887, 'colsample_bytree': 0.7625503195846945}. Best is trial 12 with value: 9.178962558649168.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb4db7-3339-4ba3-bbdb-e4c0104174b9",
   "metadata": {},
   "source": [
    "### Print the hyperparameter and objective function values for the best trial in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5efd2871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 51, 'max_depth': 7, 'learning_rate': 0.3740972645086412, 'gamma': 0.978533535354144, 'subsample': 0.845190065929861, 'colsample_bytree': 0.6009457519119111}\n"
     ]
    }
   ],
   "source": [
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cf2e753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.178962558649168\n"
     ]
    }
   ],
   "source": [
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03bf50-1309-4280-ac67-588daab087f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
